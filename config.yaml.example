# VideoLingo 配置文件 (Apple Silicon / ARM64 优化版本)
# 此配置专为 Apple Silicon Mac 的 Docker 部署优化

# ==================== 基础配置 ====================

# 界面语言
display_language: "zh-CN"

# 目标翻译语言
target_language: '简体中文'

# ==================== API 配置 ====================
# ⚠️ 重要: 请替换为你的实际 API 密钥
api:
  key: 'your-api-key-here'
  base_url: 'https://api.openai.com/v1'
  model: 'gpt-4'

# ==================== WhisperX 配置 ====================
whisper:
  # 模型选项: tiny, base, small, medium, large-v1, large-v2, large-v3
  # Apple Silicon 建议使用 medium 或 large-v3 (large-v3 更慢但更准)
  model: 'large-v3'
  
  # 语言: zh (中文), en (英文), ja (日文), auto (自动检测)
  language: 'zh'
  
  # 运行模式: ["local", "elevenlabs", "cloud"]
  # - local: 使用本地 WhisperX 模型 (需要 GPU)
  # - elevenlabs: 使用 ElevenLabs API
  # - cloud: 使用云端服务 (配置 cloud_native)
  runtime: 'local'
  
  # ElevenLabs API key
  elevenlabs_api_key: ''
  
  # 说话人分离 (Speaker Diarization) - 仅支持 cloud 模式
  # 需要部署云端服务并配置 HF_TOKEN
  diarization: false
  
  # 最小说话人数 (可选, 用于指导 diarization 模型)
  min_speakers: 
  
  # 最大说话人数 (可选, 用于指导 diarization 模型)
  max_speakers:

# ==================== 云端服务配置 ====================
# 用于 cloud 模式的 Whisper 和 Demucs 服务
# 部署 videolingo_cloud/Unified_Cloud_Server.ipynb 到 GPU 服务器 (Colab/Kaggle)
cloud_native:
  # 云端服务 URL (ngrok 或其他反向代理地址)
  cloud_url: 'YOUR_CLOUD_URL_HERE'
  
  # 访问令牌 (设置和服务端一致的 VIDEOLINGO_CLOUD_TOKEN)
  token: 'YOUR_TOKEN_HERE'

# ==================== 人声分离配置 ====================
# Demucs 人声分离 (分离人声和背景音乐)
# 
# 运行模式:
# - local: 本地运行 (需要安装 demucs 包, Apple Silicon CPU 模式较慢)
# - cloud: 使用云端服务 (推荐, 更快且节省本地资源, 使用上面的 cloud_native 配置)
# - false: 关闭人声分离
#
demucs: 'cloud'

# ==================== 字幕配置 ====================
# 是否烧录字幕到视频
burn_subtitles: true

# FFmpeg GPU 加速
# ⚠️ 在 Apple Silicon Docker 中必须设为 false
ffmpeg_gpu: false

# ==================== TTS 配置 ====================
# TTS 方法选项:
# - azure_tts: 微软 Azure TTS (推荐, 需要API密钥)
# - openai_tts: OpenAI TTS (需要API密钥)
# - edge_tts: 微软 Edge TTS (免费, 推荐)
# - fish_tts: Fish TTS
# - gpt_sovits_tts: GPT-SoVITS (需要本地部署)
# - custom_tts: 自定义TTS
tts_method: 'edge_tts'

# 说话人声音映射 (当启用说话人分离时使用)
# 可以在 Speaker Hub UI 中配置，或在这里手动设置
# 优先级: UI 配置 > 此配置
speaker_voices:
  SPEAKER_00: 'zh-CN-XiaoxiaoNeural'  # 说话人 0 的声音
  SPEAKER_01: 'zh-CN-YunxiNeural'     # 说话人 1 的声音
  # SPEAKER_02: 'zh-CN-XiaoyiNeural'  # 根据需要添加更多说话人

# ==================== 模型目录配置 ====================
# 模型缓存目录 (Docker 容器中路径)
model_dir: '/app/models'

# ==================== 性能优化配置 ====================
# 批处理大小 (Docker CPU 模式建议保持较小)
batch_size: 1

# 计算类型 (Docker CPU 模式必须使用 int8)
compute_type: 'int8'

# ==================== 其他配置 ====================
# 字幕样式 (可选)
subtitle_style:
  font: 'Noto Sans CJK SC'
  font_size: 24
  color: 'white'
  outline_color: 'black'
  outline_width: 2
  alignment: 'center'

# 视频输出分辨率 (可选, 默认保持原分辨率)
output_resolution: null

# 音频质量 (可选)
audio_quality: 'high'

# ==================== 高级配置 (一般不需要修改) ====================
# 临时文件目录
temp_dir: '/app/temp'

# 日志级别: DEBUG, INFO, WARNING, ERROR
log_level: 'INFO'

# 是否启用调试模式
debug: false
