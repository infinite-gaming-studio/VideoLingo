# WhisperX Cloud API Server - Conda Environment Configuration
# Reference: VideoLingo parent project setup
# Usage: conda env create -f environment.yml

name: whisperx-cloud
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults
dependencies:
  # ======================== Python Version ========================
  # Python 3.10 is recommended for compatibility with whisperX
  - python=3.10

  # ======================== PyTorch (CUDA 11.8) ========================
  # Using conda for PyTorch installation is more reliable for CUDA support
  # For CPU-only environment, use: cpuonly
  - pytorch=2.0.0
  - torchaudio=2.0.0
  - pytorch-cuda=11.8

  # ======================== Core Dependencies ========================
  # Audio Processing
  - librosa=0.10.2
  - pysoundfile>=0.12.1  # conda-forge 中包名为 pysoundfile
  - numpy=1.26.4

  # Data Processing
  - pandas=2.2.3

  # ======================== Pip Dependencies ========================
  # Packages not available in conda or requiring specific versions
  - pip
  - pip:
    # -------------------- ASR & Deep Learning --------------------
    # WhisperX - Main ASR engine (pinned to specific commit for stability)
    # Reference: VideoLingo/requirements.txt line 27
    - git+https://github.com/m-bain/whisperx.git@7307306a9d8dd0d261e588cc933322454f853853

    # Faster Whisper - Optimized Whisper implementation
    - faster-whisper==1.0.0

    # CTranslate2 - Fast inference engine (pinned for whisperX compatibility)
    # Reference: VideoLingo/requirements.txt line 23
    - ctranslate2==4.4.0

    # Transformers - Hugging Face transformers (pinned for compatibility)
    # Reference: VideoLingo/requirements.txt line 4
    - transformers==4.39.3

    # -------------------- API Framework --------------------
    # FastAPI - Modern web framework for building APIs
    - fastapi==0.109.0
    - uvicorn[standard]==0.27.0
    - python-multipart==0.0.6
    - pydantic==2.5.3

    # -------------------- Speaker Diarization (Optional) --------------------
    # Uncomment to enable speaker diarization feature
    # Note: Requires additional HuggingFace token for pyannote models
    # - pyannote.audio==3.1.1

    # -------------------- Tunnel & Utilities --------------------
    # pyngrok - Create public URLs for local servers
    - pyngrok
    - requests

    # -------------------- Kaggle Specific --------------------
    # nest_asyncio - Required for running async code in Kaggle notebooks
    # Only needed for Kaggle environment
    - nest_asyncio

# ======================== Environment Variables ========================
# These can be set after environment creation:
#   HF_ENDPOINT: HuggingFace mirror for China users (default: https://huggingface.co)
#   NGROK_AUTH_TOKEN: Required for public URL generation
#   CUDA_VISIBLE_DEVICES: Control GPU visibility

# ======================== Post-Setup Instructions ========================
# 1. Activate environment:
#    conda activate whisperx-cloud
#
# 2. Verify CUDA installation:
#    python -c "import torch; print(torch.cuda.is_available())"
#
# 3. Download whisperX models (first run will auto-download):
#    python -c "import whisperx; whisperx.load_model('large-v3', 'cuda')"
#
# 4. For speaker diarization, set HuggingFace token:
#    huggingface-cli login
#
# ======================== Platform Notes ========================
# Colab/Kaggle:
#   - These platforms have pre-installed CUDA, environment.yml is optional
#   - Use pip install directly for faster setup in notebooks
#
# Local GPU Server:
#   - Ensure NVIDIA drivers >= 520.61.03
#   - CUDA 11.8 toolkit will be installed via conda
#
# CPU-only:
#   - Replace pytorch-cuda=11.8 with cpuonly in channels
#   - WhisperX will run significantly slower on CPU
