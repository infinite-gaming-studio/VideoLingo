{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# VideoLingo Unified Cloud Server\n",
                "\n",
                "Combines WhisperX (ASR) + Demucs (Vocal Separation)\n",
                "\n",
                "**Steps:**\n",
                "1. Set GPU: Runtime -> Change runtime type -> GPU\n",
                "2. Paste ngrok token in Step 5\n",
                "3. Run All (Step 5 will block and keep running)\n",
                "4. Press Ctrl+C in Step 5 output to stop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install Mamba and create environment\n",
                "import os, sys\n",
                "\n",
                "ENV_PATH = '/content/conda-envs/videolingo' if 'google.colab' in sys.modules else '/kaggle/working/conda-envs/videolingo' if os.path.exists('/kaggle') else os.path.expanduser('~/conda-envs/videolingo')\n",
                "\n",
                "print(\"Installing Mamba...\")\n",
                "if not os.path.exists(os.path.expanduser('~/miniforge3/bin/mamba')):\n",
                "    !wget -q -O /tmp/miniforge.sh https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n",
                "    !bash /tmp/miniforge.sh -b -p ~/miniforge3\n",
                "\n",
                "MAMBA = os.path.expanduser('~/miniforge3/bin/mamba')\n",
                "\n",
                "print(f\"Creating env: {ENV_PATH}\")\n",
                "if os.path.exists(ENV_PATH):\n",
                "    !{MAMBA} remove -p {ENV_PATH} --all -y -q\n",
                "\n",
                "!{MAMBA} create -p {ENV_PATH} -c conda-forge -y python=3.10 ffmpeg git pip\n",
                "\n",
                "import json\n",
                "with open('.conda_python_path', 'w') as f:\n",
                "    json.dump({'python_path': f'{ENV_PATH}/bin/python', 'env_path': ENV_PATH}, f)\n",
                "\n",
                "print(\"‚úÖ Env created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Install dependencies\n",
                "import json, os, sys\n",
                "\n",
                "with open('.conda_python_path', 'r') as f:\n",
                "    cfg = json.load(f)\n",
                "    PYTHON = cfg['python_path']\n",
                "\n",
                "print(f\"Python: {PYTHON}\")\n",
                "!{PYTHON} --version\n",
                "\n",
                "print(\"\\nInstalling...\")\n",
                "!{PYTHON} -m pip install --no-input torch==2.0.0 torchaudio==2.0.0 --index-url https://download.pytorch.org/whl/cu118\n",
                "!{PYTHON} -m pip install --no-input whisperx demucs fastapi uvicorn python-multipart pyngrok librosa soundfile rich\n",
                "!{PYTHON} -m pyngrok install\n",
                "\n",
                "print(\"\\n‚úÖ Done!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 3: Verify\n",
                "import json\n",
                "\n",
                "with open('.conda_python_path', 'r') as f:\n",
                "    PYTHON = json.load(f)['python_path']\n",
                "\n",
                "print(f\"Python: {PYTHON}\")\n",
                "!{PYTHON} --version\n",
                "\n",
                "for pkg in ['torch', 'whisperx', 'demucs', 'fastapi', 'librosa', 'rich']:\n",
                "    result = !{PYTHON} -c \"import {pkg}; print('OK')\" 2>&1\n",
                "    print(f\"  {'‚úÖ' if result and result[0] == 'OK' else '‚ùå'} {pkg}\")\n",
                "\n",
                "!{PYTHON} -c \"import torch; print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 4: Download server\n",
                "import urllib.request, os, time, re\n",
                "\n",
                "url = f\"https://raw.githubusercontent.com/infinite-gaming-studio/VideoLingo/main/videolingo_cloud/unified_server.py?t={int(time.time())}\"\n",
                "\n",
                "# Remove old version if exists\n",
                "if os.path.exists('unified_server.py'):\n",
                "    os.remove('unified_server.py')\n",
                "\n",
                "print(f\"Downloading from: {url}\")\n",
                "urllib.request.urlretrieve(url, 'unified_server.py')\n",
                "\n",
                "# Extract and print version directly from content\n",
                "with open('unified_server.py', 'r', encoding='utf-8') as f:\n",
                "    content = f.read()\n",
                "    version_match = re.search(r'SERVER_VERSION = \"(.*?)\"', content)\n",
                "    version = version_match.group(1) if version_match else \"unknown\"\n",
                "    print(f\"‚úÖ Downloaded unified_server.py v{version}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 5: Run server (BLOCKING - Ctrl+C to stop)\n",
                "NGROK_TOKEN = \"\"\n",
                "SERVER_TOKEN = \"\"  \n",
                "\n",
                "if not NGROK_TOKEN:\n",
                "    raise ValueError('Paste ngrok token above')\n",
                "\n",
                "import os, json\n",
                "with open('.conda_python_path', 'r') as f:\n",
                "    cfg = json.load(f)\n",
                "    PYTHON = cfg['python_path']\n",
                "    ENV_PATH = cfg['env_path']\n",
                "\n",
                "os.environ['NGROK_TOKEN'] = NGROK_TOKEN\n",
                "\n",
                "# ËÆæÁΩÆÊúçÂä°Âô®ËÆøÈóÆ‰ª§ÁâåÔºàÂèØÈÄâÔºâ\n",
                "if SERVER_TOKEN:\n",
                "    os.environ['WHISPER_SERVER_TOKEN'] = SERVER_TOKEN\n",
                "    print(\"üîí Token authentication enabled\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Warning: No SERVER_TOKEN set, server will accept all requests\")\n",
                "\n",
                "# Add conda site-packages to path for direct execution if needed\n",
                "os.environ['PYTHONPATH'] = f\"{ENV_PATH}/lib/python3.10/site-packages:\" + os.environ.get('PYTHONPATH', '')\n",
                "\n",
                "print(f\"Starting server with {PYTHON}...\")\n",
                "!{PYTHON} unified_server.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}